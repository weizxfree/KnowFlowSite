---
sidebar_position: 2
---

# 👥 用户管理

## 🔐 注册新用户

### 访问后台管理系统

| 项目 | 信息 |
|------|------|
| **访问地址** | http://localhost:8888 |
| **初始账号** | admin |
| **初始密码** | 12345678 |

### 创建用户步骤

1. 登录后台管理系统
2. 进入「用户管理」菜单
3. 点击「新建用户」
4. 填写用户信息并保存

:::tip 建议
考虑到后续嵌入模型配置、知识库创建的身份均是以初始用户的身份执行，推荐将此用户定义为管理员用户，即采用 `(admin/lab)` 公共账户的命名方式，而非具体用户。
:::

## 👨‍👩‍👧‍👦 创建其它用户

### 用户创建流程

1. **配置初始用户** - 完成管理员用户的基础配置
2. **返回后台系统** - 继续创建其他业务用户
3. **自动继承配置** - 新用户自动使用初始用户的模型配置
4. **团队管理** - 通过团队管理菜单调整用户归属

### 团队协作特性

| 特性 | 说明 |
|------|------|
| **配置继承** | 新用户自动使用初始用户的模型配置 |
| **自动加入团队** | 新用户自动加入对应团队 |
| **知识库共享** | 团队成员可共享知识库信息 |
| **权限管理** | 支持团队成员的添加和移除 |

## ⚙️ 初始用户模型配置

:::warning 重要提醒
在创建其他用户前，请先完成初始用户的模型配置，确保后续用户能正常继承配置。
:::

### 访问前台系统

**访问地址**: http://localhost:80

### 必需配置项

需要配置以下两个核心模型：

- 🔍 **Embedding 模型** - 用于文档向量化和语义搜索
- 💬 **Chat 模型** - 用于对话生成和问答

### 🔍 Embedding 模型配置

:::info 模型支持
当前仅支持 **bge-m3** 模型，提供两种部署方式供选择。
:::

#### 方式一：本地部署（Ollama）

**步骤 1**: 拉取模型
```bash
ollama pull bge-m3:latest
```

**步骤 2**: 前台配置

| 配置项 | 值 |
|--------|----|
| **模型名称** | `bge-m3` |
| **URL 地址** | `http://host.docker.internal:11434` |

#### 方式二：在线 API（推荐）

**平台**: 硅基流动 - bge-m3 模型免费调用

**平台地址**: https://cloud.siliconflow.cn/i/bjDoFhPf

**配置步骤**:
1. 注册并获取 API KEY
2. 在模型选择菜单中输入 API KEY
3. 选择 bge-m3 模型

:::tip 推荐方案
推荐使用硅基流动平台，免费且稳定，无需本地部署。
:::

### 💬 Chat 模型配置

Chat 模型配置方式与 Embedding 模型类似，支持多种主流模型：

- **本地部署**: 通过 Ollama 部署开源模型
- **在线 API**: 支持 OpenAI、Claude、国产大模型等
- **推荐模型**: GPT-4、Claude-3、Qwen 等

:::note 配置说明
具体配置步骤与 Embedding 模型相同，根据选择的模型平台获取相应的 API KEY 即可。
:::